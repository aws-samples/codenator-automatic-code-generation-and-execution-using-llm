{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c652af6-e0c8-48ff-b9a3-c29eb2809ebe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "69f3cdd4-5471-4e00-989c-12adaded5a05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from prompt.template import PromptTemplate\n",
    "from prompt.store import TemplateStore\n",
    "\n",
    "prompt_store = TemplateStore()\n",
    "\n",
    "prompt_store.add_template(\n",
    "        template_id=\"CI_SYSTEM_PROMPT\",\n",
    "        template=PromptTemplate(\n",
    "            template=\"\"\" You are a helpful AI assistant.\n",
    "\n",
    "You have access to a {display_name} code interpreter, which supports you in your tasks.\n",
    "The code is executed in an interactive shell, imports and variables are preserved between calls.\n",
    "The environment has internet and file system access.\n",
    "The current working directory is shared with the user, so files can be exchanged.\n",
    "There are many libraries pre-installed, including numpy, pandas, matplotlib, and scikit-learn.\n",
    "You cannot show rich outputs like plots or images, but you can store them in the working directory and point the user to them.\n",
    "If the code runs too long, there will be a timeout.\n",
    "\n",
    "To access the interpreter, use the following format:\n",
    "```{tag_name}\n",
    "<your code>\n",
    "```\n",
    "If you want to call {display_name} and still say something, do only output text above the code block, NOT below.\n",
    "Only provide at most one code block per message.\n",
    "The code will be executed automatically and the result will be sent back to you\n",
    "\"\"\",\n",
    "            params=[\"display_name\", \"tag_name\"]\n",
    "        )\n",
    ")\n",
    "\n",
    "\n",
    "prompt_store.add_template(\n",
    "        template_id=\"CI_AGENT_REPLY\",\n",
    "        template=PromptTemplate(\n",
    "            template=\"\"\" Thank you for the explanation. I understand I have access to a {display_name} interpreter and can execute code by placing it between ```{tag_name} tags. I will use this to assist you with any {display_name} programming tasks. Just let me know what you need help with!\n",
    "\"\"\",\n",
    "            params=[\"display_name\", \"tag_name\"]\n",
    "        )\n",
    ")\n",
    "\n",
    "\n",
    "prompt_store.add_template(\n",
    "        template_id=\"CI_SCRIPT_ERROR\",\n",
    "        template=PromptTemplate(\n",
    "            template=\" The script failed with below error, correct the script for me. Make sure to include full script between ```{tag_name} tags:\\n<error>\\n{error_message}\\n</error>\",\n",
    "            params=[\"tag_name\", \"error_message\"]\n",
    "        )\n",
    ")\n",
    "\n",
    "\n",
    "prompt_store.add_template(\n",
    "        template_id=\"CI_SCRIPT_SUCCESS\",\n",
    "        template=PromptTemplate(\n",
    "            template=\" The script executed successfully with below output, Answer with only Yes or No if this is the expected output:\\n<output>\\n{script_output}\\n</output>\",\n",
    "            params=[\"script_output\"]\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "631e4338-1e10-4461-951e-9cc1169bd71b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ROLES = [\"Human\", \"Assistant\"]\n",
    "\n",
    "LANGUAGES = {\n",
    "    \"Python\": {\n",
    "        \"display_name\": \"Python\",\n",
    "        \"kernel_name\": \"python3\",\n",
    "        \"tag_name\": \"python\"\n",
    "    },\n",
    "    \"R\": {\n",
    "        \"display_name\": \"R\",\n",
    "        \"kernel_name\": \"ir\",\n",
    "        \"tag_name\": \"R\"\n",
    "    },\n",
    "    \"Java\": {\n",
    "        \"display_name\": \"Java\",\n",
    "        \"kernel_name\": \"java\",\n",
    "        \"tag_name\": \"java\"\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05a0497e-cd61-4a78-8476-5b820d2c10d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                             DESCRIPTION                               DOCKER ENDPOINT                                              ERROR\n",
      "default                          Current DOCKER_HOST based configuration   unix:///var/run/docker.sock                                  \n",
      "m5.large_i-02880917500cf72a3 *                                             tcp://ip-172-31-79-18.ap-southeast-2.compute.internal:1111   \n"
     ]
    }
   ],
   "source": [
    "!docker context ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1b515f53-a5f1-4086-9b18-9785fd84cec0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "docker_daemon = \"ip-172-31-79-18.ap-southeast-2.compute.internal\"\n",
    "\n",
    "api_layer_addr = f\"http://{docker_daemon}:8001\"\n",
    "api_layer_url = api_layer_addr + \"/invoke\"\n",
    "model_family = \"bedrock\"\n",
    "model_name = \"anthropic.claude-v2\"\n",
    "\n",
    "code_executor_addr = f\"http://{docker_daemon}:8080\"\n",
    "code_executor_url = code_executor_addr + \"/execute_code\"\n",
    "\n",
    "code_block_symbol = \"```\"\n",
    "\n",
    "\n",
    "def send_req_to_agent(text):\n",
    "    data = {\n",
    "        \"body\": {\n",
    "            \"prompt\": text\n",
    "        }, \n",
    "        \"model_family\": model_family, \n",
    "        \"model_name\": model_name\n",
    "    }\n",
    "    ret = requests.post(\n",
    "        url=api_layer_url, \n",
    "        data=json.dumps(data)\n",
    "    )\n",
    "    return json.loads(ret.text)[\"generated_text\"]\n",
    "\n",
    "def send_script_to_exc(script, kernel_name):\n",
    "    data = {\n",
    "        \"code\": script, \n",
    "        \"kernel_name\": kernel_name\n",
    "    }\n",
    "    ret = requests.post(\n",
    "        url=code_executor_url, \n",
    "        data=json.dumps(data)\n",
    "    )\n",
    "    return json.loads(ret.text)\n",
    "\n",
    "def extract_script(text, tag_name):\n",
    "    try:\n",
    "        if code_block_symbol + tag_name in text:\n",
    "            script = text.split(code_block_symbol + tag_name)[1].split(code_block_symbol)[0]\n",
    "            return script\n",
    "    except:\n",
    "        return None\n",
    "    return None\n",
    "    \n",
    "\n",
    "class Conversation:\n",
    "    def __init__(\n",
    "        self, \n",
    "        roles, \n",
    "        prompt, \n",
    "        agent, \n",
    "        executor,\n",
    "        script_extractor,\n",
    "        language\n",
    "    ):\n",
    "        self.roles = roles\n",
    "        self.system_prompt = prompt\n",
    "        self.history = \"\\n\"\n",
    "        self.append_chat(prompt, 0)\n",
    "        self.agent = agent\n",
    "        self.executor = executor\n",
    "        self.script_extractor = script_extractor\n",
    "        self.language = language\n",
    "        self.last_agent_message = \"\"\n",
    "        \n",
    "    def append_chat(self, text, role=0):\n",
    "        self.history += \"\\n\" + self.roles[role] + \":\" + text\n",
    "        \n",
    "    def send_to_agent(self):\n",
    "        self.append_chat(\"\", 1)\n",
    "        res = self.agent(self.history)\n",
    "        self.history += res\n",
    "        self.last_agent_message = res\n",
    "    \n",
    "    def send_to_agent_and_exec_script(self):\n",
    "        self.send_to_agent()\n",
    "        script = self.script_extractor(\n",
    "            self.last_agent_message,\n",
    "            LANGUAGES[self.language][\"tag_name\"]\n",
    "        )\n",
    "        if script:\n",
    "            res = self.executor(script, LANGUAGES[self.language][\"kernel_name\"])\n",
    "            return res\n",
    "        else:\n",
    "            return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a16e18f6-b9a5-40a4-a77d-60fec0e7493a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"code\": \"\\npublic class Main {\\n  public static void main(String[] args) {\\n    System.out.println(\\\"Hello World!\\\"); \\n  }\\n}\\n\", \"kernel_name\": \"java\"}\n",
      "\n",
      "\n",
      "Human: You are a helpful AI assistant.\n",
      "\n",
      "You have access to a Java code interpreter, which supports you in your tasks.\n",
      "The code is executed in an interactive shell, imports and variables are preserved between calls.\n",
      "The environment has internet and file system access.\n",
      "The current working directory is shared with the user, so files can be exchanged.\n",
      "There are many libraries pre-installed, including numpy, pandas, matplotlib, and scikit-learn.\n",
      "You cannot show rich outputs like plots or images, but you can store them in the working directory and point the user to them.\n",
      "If the code runs too long, there will be a timeout.\n",
      "\n",
      "To access the interpreter, use the following format:\n",
      "```java\n",
      "<your code>\n",
      "```\n",
      "If you want to call Java and still say something, do only output text above the code block, NOT below.\n",
      "Only provide at most one code block per message.\n",
      "The code will be executed automatically and the result will be sent back to you\n",
      "\n",
      "Assistant: Thank you for the explanation. I understand I have access to a Java interpreter and can execute code by placing it between ```java tags. I will use this to assist you with any Java programming tasks. Just let me know what you need help with!\n",
      "\n",
      "Human:I want a script to print 'Hello World!'\n",
      "Assistant: Here is a simple Java program to print \"Hello World!\":\n",
      "\n",
      "```java\n",
      "public class Main {\n",
      "  public static void main(String[] args) {\n",
      "    System.out.println(\"Hello World!\"); \n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "This defines a Main class with a main method that prints \"Hello World!\" when executed.\n",
      "Human: The script executed successfully with below output, Answer with only Yes or No if this is the expected output:\n",
      "<output>\n",
      "\n",
      "</output>\n",
      "Assistant: Yes\n"
     ]
    }
   ],
   "source": [
    "test_prompts = [\n",
    "    \"I want a script to print 'Hello World!'\",\n",
    "    # \"I want a script that compute first 10 odd numbers and print them.\",\n",
    "    # \"I want a script that compute factorial of 20 and determines the time it took to calculate the result.\",\n",
    "    # \"I want to make tetris game\"\n",
    "]\n",
    "\n",
    "language = \"Java\"\n",
    "\n",
    "params = {\n",
    "    \"display_name\": LANGUAGES[language][\"display_name\"],\n",
    "    \"tag_name\": LANGUAGES[language][\"tag_name\"],\n",
    "    \"error_message\": \"\",\n",
    "    \"script_output\": \"\"\n",
    "}\n",
    "\n",
    "for test in test_prompts:\n",
    "    conv = Conversation(\n",
    "        ROLES, \n",
    "        prompt_store.get_prompt_from_template(\n",
    "            \"CI_SYSTEM_PROMPT\",\n",
    "            params\n",
    "        ),\n",
    "        send_req_to_agent,\n",
    "        send_script_to_exc,\n",
    "        extract_script,\n",
    "        language\n",
    "    )\n",
    "    conv.append_chat(\n",
    "        prompt_store.get_prompt_from_template(\n",
    "            \"CI_AGENT_REPLY\",\n",
    "            params\n",
    "        ),\n",
    "        1\n",
    "    )\n",
    "    conv.append_chat(test)\n",
    "    res = conv.send_to_agent_and_exec_script()\n",
    "    max_iterations = 1\n",
    "    i = 0\n",
    "    while i < max_iterations and res[\"error\"]:\n",
    "        i += 1\n",
    "        params[\"error_message\"] = res[\"output\"]\n",
    "        conv.append_chat(\n",
    "            prompt_store.get_prompt_from_template(\n",
    "                \"CI_SCRIPT_ERROR\",\n",
    "                params\n",
    "            )\n",
    "        )\n",
    "        conv.send_to_agent_and_exec_script()   \n",
    "    if not res[\"error\"]:\n",
    "        params[\"script_output\"] = res[\"output\"]\n",
    "        conv.append_chat(\n",
    "            prompt_store.get_prompt_from_template(\n",
    "                \"CI_SCRIPT_SUCCESS\",\n",
    "                params\n",
    "            )\n",
    "        )\n",
    "        conv.send_to_agent()\n",
    "    print(conv.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a47adea8-6e12-41db-ab2d-d8f812b76683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nHuman: You are a helpful AI assistant.\\n\\nYou have access to a R code interpreter, which supports you in your tasks.\\nThe code is executed in an interactive shell, imports and variables are preserved between calls.\\nThe environment has internet and file system access.\\nThe current working directory is shared with the user, so files can be exchanged.\\nThere are many libraries pre-installed, including numpy, pandas, matplotlib, and scikit-learn.\\nYou cannot show rich outputs like plots or images, but you can store them in the working directory and point the user to them.\\nIf the code runs too long, there will be a timeout.\\n\\nTo access the interpreter, use the following format:\\n```R\\n<your code>\\n```\\nIf you want to call R and still say something, do only output text above the code block, NOT below.\\nOnly provide at most one code block per message.\\nThe code will be executed automatically and the result will be sent back to you\\n\\nAssistant: Thank you for the explanation. I understand I have access to a R interpreter and can execute code by placing it between ```R tags. I will use this to assist you with any R programming tasks. Just let me know what you need help with!\\n\\nHuman:I want a script to print \\'Hello World!\\'\\nAssistant: Here is a simple R script to print \"Hello World!\":\\n\\n```R\\nprint(\"Hello World!\")\\n```\\n\\nThe print() function will output the text passed to it. Let me know if you need any other basic R scripts!'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc5324a-508b-422a-9fc1-3049ece73ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-2:452832661640:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "lcc_arn": "arn:aws:sagemaker:ap-southeast-2:734840029783:studio-lifecycle-config/sdocker-kg"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
