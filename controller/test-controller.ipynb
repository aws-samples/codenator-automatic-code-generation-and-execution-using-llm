{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16c89da9-55fe-47b9-9f00-022df17001f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('app')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "64f4ea44-bc27-4192-bead-52b2553736de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1867ef59bb6246c4'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "uuid.uuid4().hex[:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c652af6-e0c8-48ff-b9a3-c29eb2809ebe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CI_SYSTEM_PROMPT': ' You are a helpful AI assistant.\\nYou have access to a {display_name} code interpreter, which supports you in your tasks.\\nThe code is executed in an interactive shell, imports and variables are preserved between calls.\\nThe environment has internet and file system access.\\nThe current working directory is shared with the user, so files can be exchanged.\\nThere are many libraries pre-installed, including numpy, pandas, matplotlib, and scikit-learn.\\nYou cannot show rich outputs like plots or images, but you can store them in the working directory and point the user to them.\\nIf the code runs too long, there will be a timeout.\\n\\nTo access the interpreter, use the following format:\\n```{tag_name}\\n<your code>\\n```\\n{language_instructions}\\nReport expected output and enclose it within a <output></output> tag.\\nIf you want to call {display_name} and still say something, do only output text above the code block, NOT below.\\nOnly provide at most one code block per message.\\nThe code will be executed automatically and the result will be sent back to you', 'CI_AGENT_REPLY': ' Thank you for the explanation. I understand I have access to a {display_name} interpreter and can execute code by placing it between ```{tag_name} tags then return expected output between <output></output> tags. I will use this to assist you with any {display_name} programming tasks. Just let me know what you need help with!', 'CI_SCRIPT_ERROR': ' The script failed with below error, correct the script for me. Make sure to include full script between ```{tag_name} tags:\\n<error>\\n{error_message}\\n</error>', 'CI_SCRIPT_SUCCESS': ' The script executed successfully with below output, Answer with only Yes or No if this is the expected output:\\n<output>\\n{script_output}\\n</output>'}\n"
     ]
    }
   ],
   "source": [
    "from prompt.store import TemplateStore\n",
    "\n",
    "prompt_store = TemplateStore()\n",
    "prompt_store.read_from_json(\"prompt/database.json\")\n",
    "print(prompt_store1.database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69f3cdd4-5471-4e00-989c-12adaded5a05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from prompt.template import PromptTemplate\n",
    "from prompt.store import TemplateStore\n",
    "\n",
    "prompt_store = TemplateStore()\n",
    "\n",
    "prompt_store.add_template(\n",
    "        template_id=\"CI_SYSTEM_PROMPT\",\n",
    "        template=PromptTemplate(\n",
    "            template=\"\"\" You are a helpful AI assistant.\n",
    "\n",
    "You have access to a {display_name} code interpreter, which supports you in your tasks.\n",
    "The code is executed in an interactive shell, imports and variables are preserved between calls.\n",
    "The environment has internet and file system access.\n",
    "The current working directory is shared with the user, so files can be exchanged.\n",
    "There are many libraries pre-installed, including numpy, pandas, matplotlib, and scikit-learn.\n",
    "You cannot show rich outputs like plots or images, but you can store them in the working directory and point the user to them.\n",
    "If the code runs too long, there will be a timeout.\n",
    "\n",
    "To access the interpreter, use the following format:\n",
    "```{tag_name}\n",
    "<your code>\n",
    "```\n",
    "{language_instructions}\n",
    "Report expected output and enclose it within a <output></output> tag.\n",
    "If you want to call {display_name} and still say something, do only output text above the code block, NOT below.\n",
    "Only provide at most one code block per message.\n",
    "The code will be executed automatically and the result will be sent back to you\n",
    "\"\"\",\n",
    "            params=[\"display_name\", \"tag_name\", \"language_instructions\"]\n",
    "        )\n",
    ")\n",
    "\n",
    "\n",
    "prompt_store.add_template(\n",
    "        template_id=\"CI_AGENT_REPLY\",\n",
    "        template=PromptTemplate(\n",
    "            template=\"\"\" Thank you for the explanation. I understand I have access to a {display_name} interpreter and can execute code by placing it between ```{tag_name} tags then return expected output between <output></output> tags. I will use this to assist you with any {display_name} programming tasks. Just let me know what you need help with!\n",
    "\"\"\",\n",
    "            params=[\"display_name\", \"tag_name\"]\n",
    "        )\n",
    ")\n",
    "\n",
    "\n",
    "prompt_store.add_template(\n",
    "        template_id=\"CI_SCRIPT_ERROR\",\n",
    "        template=PromptTemplate(\n",
    "            template=\" The script failed with below error, correct the script for me. Make sure to include full script between ```{tag_name} tags:\\n<error>\\n{error_message}\\n</error>\",\n",
    "            params=[\"tag_name\", \"error_message\"]\n",
    "        )\n",
    ")\n",
    "\n",
    "\n",
    "prompt_store.add_template(\n",
    "        template_id=\"CI_SCRIPT_SUCCESS\",\n",
    "        template=PromptTemplate(\n",
    "            template=\" The script executed successfully with below output, Answer with only Yes or No if this is the expected output:\\n<output>\\n{script_output}\\n</output>\",\n",
    "            params=[\"script_output\"]\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "631e4338-1e10-4461-951e-9cc1169bd71b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ROLES = [\"Human\", \"Assistant\"]\n",
    "\n",
    "LANGUAGES = {\n",
    "    \"Python\": {\n",
    "        \"display_name\": \"Python\",\n",
    "        \"kernel_name\": \"python3\",\n",
    "        \"tag_name\": \"python\",\n",
    "        \"language_instructions\": \"\",\n",
    "        \"pre_exec_script\": None,\n",
    "        \"post_exec_script\": None\n",
    "    },\n",
    "    \"R\": {\n",
    "        \"display_name\": \"R\",\n",
    "        \"kernel_name\": \"ir\",\n",
    "        \"tag_name\": \"R\",\n",
    "        \"language_instructions\":\"\",\n",
    "        \"pre_exec_script\": None,\n",
    "        \"post_exec_script\": None\n",
    "    },\n",
    "    \"Java\": {\n",
    "        \"display_name\": \"Java\",\n",
    "        \"kernel_name\": \"java\",\n",
    "        \"tag_name\": \"java\",\n",
    "        \"language_instructions\": \"Always use \\\"Main\\\" as class name.\",\n",
    "        \"pre_exec_script\": None,\n",
    "        \"post_exec_script\": \"Main.main(new String[] {})\"\n",
    "    },\n",
    "    \"JavaScript\": {\n",
    "        \"display_name\": \"JavaScript\",\n",
    "        \"kernel_name\": \"javascript\",\n",
    "        \"tag_name\": \"js\",\n",
    "        \"language_instructions\": \"\",\n",
    "        \"pre_exec_script\": None,\n",
    "        \"post_exec_script\": None\n",
    "    },\n",
    "    \"Bash\": {\n",
    "        \"display_name\": \"Bash\",\n",
    "        \"kernel_name\": \"bash\",\n",
    "        \"tag_name\": \"bash\",\n",
    "        \"language_instructions\": \"\",\n",
    "        \"pre_exec_script\": None,\n",
    "        \"post_exec_script\": None\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88fa39ef-aa74-4b7f-871d-d27114dd9ee0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"languages.json\", \"w\") as json_f:\n",
    "    json.dump(LANGUAGES, json_f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "05a0497e-cd61-4a78-8476-5b820d2c10d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                              DESCRIPTION                               DOCKER ENDPOINT                                               ERROR\n",
      "default                           Current DOCKER_HOST based configuration   unix:///var/run/docker.sock                                   \n",
      "m5.xlarge_i-0041d74c0c6372fd4 *                                             tcp://ip-172-31-76-106.ap-southeast-2.compute.internal:1111   \n"
     ]
    }
   ],
   "source": [
    "!docker context ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1b515f53-a5f1-4086-9b18-9785fd84cec0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "docker_daemon = \"ip-172-31-76-106.ap-southeast-2.compute.internal\"\n",
    "\n",
    "api_layer_addr = f\"http://{docker_daemon}:8001\"\n",
    "api_layer_url = api_layer_addr + \"/invoke\"\n",
    "model_family = \"bedrock\"\n",
    "model_name = \"anthropic.claude-v2\"\n",
    "\n",
    "code_executor_addr = f\"http://{docker_daemon}:8080\"\n",
    "code_executor_url = code_executor_addr + \"/execute_code\"\n",
    "\n",
    "code_block_symbol = \"```\"\n",
    "output_tags = [\"<output>\", \"</output>\"]\n",
    "\n",
    "\n",
    "def send_req_to_agent(text):\n",
    "    data = {\n",
    "        \"body\": {\n",
    "            \"prompt\": text\n",
    "        }, \n",
    "        \"model_family\": model_family, \n",
    "        \"model_name\": model_name\n",
    "    }\n",
    "    ret = requests.post(\n",
    "        url=api_layer_url, \n",
    "        data=json.dumps(data)\n",
    "    )\n",
    "    return json.loads(ret.text)[\"generated_text\"]\n",
    "\n",
    "def send_script_to_exc(script, kernel_name):\n",
    "    data = {\n",
    "        \"code\": script, \n",
    "        \"kernel_name\": kernel_name\n",
    "    }\n",
    "    ret = requests.post(\n",
    "        url=code_executor_url, \n",
    "        data=json.dumps(data)\n",
    "    )\n",
    "    return json.loads(ret.text)\n",
    "\n",
    "def extract_script(text, tag_name):\n",
    "    try:\n",
    "        if code_block_symbol + tag_name in text:\n",
    "            script = text.split(code_block_symbol + tag_name + \"\\n\")[1].split(code_block_symbol)[0]\n",
    "            expected_output = \"\"\n",
    "            if output_tags[0] in text and output_tags[1] in text:\n",
    "                expected_output = text.split(output_tags[0])[1].split(output_tags[1])[0]\n",
    "            return (script, expected_output)\n",
    "    except:\n",
    "        return None\n",
    "    return None\n",
    "    \n",
    "\n",
    "class Conversation:\n",
    "    def __init__(\n",
    "        self, \n",
    "        roles, \n",
    "        prompt, \n",
    "        agent, \n",
    "        executor,\n",
    "        script_extractor,\n",
    "        language\n",
    "    ):\n",
    "        self.roles = roles\n",
    "        self.system_prompt = prompt\n",
    "        self.history = \"\\n\"\n",
    "        self.append_chat(prompt, 0)\n",
    "        self.agent = agent\n",
    "        self.executor = executor\n",
    "        self.script_extractor = script_extractor\n",
    "        self.language = language\n",
    "        self.last_agent_message = \"\"\n",
    "        \n",
    "    def append_chat(self, text, role=0):\n",
    "        self.history += \"\\n\" + self.roles[role] + \":\" + text\n",
    "        \n",
    "    def send_to_agent(self):\n",
    "        self.append_chat(\"\", 1)\n",
    "        res = self.agent(self.history)\n",
    "        self.history += res\n",
    "        self.last_agent_message = res\n",
    "    \n",
    "    def send_to_agent_and_exec_script(self):\n",
    "        self.send_to_agent()\n",
    "        result = self.script_extractor(\n",
    "            self.last_agent_message,\n",
    "            LANGUAGES[self.language][\"tag_name\"]\n",
    "        )\n",
    "        if result:\n",
    "            script, expected_output = result\n",
    "            output_res = \"\"\n",
    "            if LANGUAGES[self.language][\"pre_exec_script\"]:\n",
    "                output_res += self.executor(\n",
    "                    LANGUAGES[self.language][\"pre_exec_script\"], \n",
    "                    LANGUAGES[self.language][\"kernel_name\"]\n",
    "                )[\"output\"]\n",
    "            res = self.executor(script, LANGUAGES[self.language][\"kernel_name\"])\n",
    "            res[\"output\"] = output_res + res[\"output\"]\n",
    "            if LANGUAGES[self.language][\"post_exec_script\"]:\n",
    "                res[\"output\"] += self.executor(\n",
    "                    LANGUAGES[self.language][\"post_exec_script\"], \n",
    "                    LANGUAGES[self.language][\"kernel_name\"]\n",
    "                )[\"output\"]\n",
    "            return res\n",
    "        else:\n",
    "            return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a16e18f6-b9a5-40a4-a77d-60fec0e7493a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Human: You are a helpful AI assistant.\n",
      "\n",
      "You have access to a Python code interpreter, which supports you in your tasks.\n",
      "The code is executed in an interactive shell, imports and variables are preserved between calls.\n",
      "The environment has internet and file system access.\n",
      "The current working directory is shared with the user, so files can be exchanged.\n",
      "There are many libraries pre-installed, including numpy, pandas, matplotlib, and scikit-learn.\n",
      "You cannot show rich outputs like plots or images, but you can store them in the working directory and point the user to them.\n",
      "If the code runs too long, there will be a timeout.\n",
      "\n",
      "To access the interpreter, use the following format:\n",
      "```python\n",
      "<your code>\n",
      "```\n",
      "\n",
      "Report expected output and enclose it within a <output></output> tag.\n",
      "If you want to call Python and still say something, do only output text above the code block, NOT below.\n",
      "Only provide at most one code block per message.\n",
      "The code will be executed automatically and the result will be sent back to you\n",
      "\n",
      "Assistant: Thank you for the explanation. I understand I have access to a Python interpreter and can execute code by placing it between ```python tags then return expected output between <output></output> tags. I will use this to assist you with any Python programming tasks. Just let me know what you need help with!\n",
      "\n",
      "Human:I want a script to print 'Hello World!'\n",
      "Assistant: Here is a Python script to print 'Hello World!':\n",
      "\n",
      "```python\n",
      "print('Hello World!')\n",
      "```\n",
      "\n",
      "<output>\n",
      "Hello World!\n",
      "</output>\n",
      "\n",
      "To print 'Hello World!', we use the print() function in Python and pass the string 'Hello World!' as an argument. This will output the text to the console.\n",
      "Human: The script executed successfully with below output, Answer with only Yes or No if this is the expected output:\n",
      "<output>\n",
      "Hello World!\n",
      "</output>\n",
      "Assistant: Yes\n",
      "\n",
      "\n",
      "Human: You are a helpful AI assistant.\n",
      "\n",
      "You have access to a R code interpreter, which supports you in your tasks.\n",
      "The code is executed in an interactive shell, imports and variables are preserved between calls.\n",
      "The environment has internet and file system access.\n",
      "The current working directory is shared with the user, so files can be exchanged.\n",
      "There are many libraries pre-installed, including numpy, pandas, matplotlib, and scikit-learn.\n",
      "You cannot show rich outputs like plots or images, but you can store them in the working directory and point the user to them.\n",
      "If the code runs too long, there will be a timeout.\n",
      "\n",
      "To access the interpreter, use the following format:\n",
      "```R\n",
      "<your code>\n",
      "```\n",
      "\n",
      "Report expected output and enclose it within a <output></output> tag.\n",
      "If you want to call R and still say something, do only output text above the code block, NOT below.\n",
      "Only provide at most one code block per message.\n",
      "The code will be executed automatically and the result will be sent back to you\n",
      "\n",
      "Assistant: Thank you for the explanation. I understand I have access to a R interpreter and can execute code by placing it between ```R tags then return expected output between <output></output> tags. I will use this to assist you with any R programming tasks. Just let me know what you need help with!\n",
      "\n",
      "Human:I want a script to print 'Hello World!'\n",
      "Assistant: Here is a simple R script to print \"Hello World!\":\n",
      "\n",
      "```R\n",
      "print(\"Hello World!\")\n",
      "```\n",
      "\n",
      "<output>\n",
      "[1] \"Hello World!\"\n",
      "</output>\n",
      "\n",
      "This uses the print() function in R to output the text \"Hello World!\". The [1] indicates it is printing the first element of the character vector passed to print().\n",
      "Human: The script executed successfully with below output, Answer with only Yes or No if this is the expected output:\n",
      "<output>\n",
      "[1] \"Hello World!\"\n",
      "</output>\n",
      "Assistant: Yes\n",
      "\n",
      "\n",
      "Human: You are a helpful AI assistant.\n",
      "\n",
      "You have access to a Java code interpreter, which supports you in your tasks.\n",
      "The code is executed in an interactive shell, imports and variables are preserved between calls.\n",
      "The environment has internet and file system access.\n",
      "The current working directory is shared with the user, so files can be exchanged.\n",
      "There are many libraries pre-installed, including numpy, pandas, matplotlib, and scikit-learn.\n",
      "You cannot show rich outputs like plots or images, but you can store them in the working directory and point the user to them.\n",
      "If the code runs too long, there will be a timeout.\n",
      "\n",
      "To access the interpreter, use the following format:\n",
      "```java\n",
      "<your code>\n",
      "```\n",
      "Always use \"Main\" as class name.\n",
      "Report expected output and enclose it within a <output></output> tag.\n",
      "If you want to call Java and still say something, do only output text above the code block, NOT below.\n",
      "Only provide at most one code block per message.\n",
      "The code will be executed automatically and the result will be sent back to you\n",
      "\n",
      "Assistant: Thank you for the explanation. I understand I have access to a Java interpreter and can execute code by placing it between ```java tags then return expected output between <output></output> tags. I will use this to assist you with any Java programming tasks. Just let me know what you need help with!\n",
      "\n",
      "Human:I want a script to print 'Hello World!'\n",
      "Assistant: Here is a simple Java program to print \"Hello World!\":\n",
      "\n",
      "```java\n",
      "public class Main {\n",
      "  public static void main(String[] args) {\n",
      "    System.out.println(\"Hello World!\"); \n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "<output>\n",
      "Hello World!\n",
      "</output>\n",
      "\n",
      "This uses the System.out.println() method to print the text \"Hello World!\" to the console. The main() method is the entry point for the Java program, and printing to System.out writes to the standard output stream.\n",
      "Human: The script executed successfully with below output, Answer with only Yes or No if this is the expected output:\n",
      "<output>\n",
      "Hello World!\n",
      "</output>\n",
      "Assistant: Yes\n",
      "\n",
      "\n",
      "Human: You are a helpful AI assistant.\n",
      "\n",
      "You have access to a JavaScript code interpreter, which supports you in your tasks.\n",
      "The code is executed in an interactive shell, imports and variables are preserved between calls.\n",
      "The environment has internet and file system access.\n",
      "The current working directory is shared with the user, so files can be exchanged.\n",
      "There are many libraries pre-installed, including numpy, pandas, matplotlib, and scikit-learn.\n",
      "You cannot show rich outputs like plots or images, but you can store them in the working directory and point the user to them.\n",
      "If the code runs too long, there will be a timeout.\n",
      "\n",
      "To access the interpreter, use the following format:\n",
      "```js\n",
      "<your code>\n",
      "```\n",
      "\n",
      "Report expected output and enclose it within a <output></output> tag.\n",
      "If you want to call JavaScript and still say something, do only output text above the code block, NOT below.\n",
      "Only provide at most one code block per message.\n",
      "The code will be executed automatically and the result will be sent back to you\n",
      "\n",
      "Assistant: Thank you for the explanation. I understand I have access to a JavaScript interpreter and can execute code by placing it between ```js tags then return expected output between <output></output> tags. I will use this to assist you with any JavaScript programming tasks. Just let me know what you need help with!\n",
      "\n",
      "Human:I want a script to print 'Hello World!'\n",
      "Assistant: Here is a simple JavaScript script to print 'Hello World!':\n",
      "\n",
      "```js\n",
      "console.log('Hello World!');\n",
      "```\n",
      "\n",
      "<output>\n",
      "Hello World!\n",
      "</output>\n",
      "\n",
      "To print 'Hello World!' in JavaScript, you can use console.log() and pass the string 'Hello World!' as a parameter. This will output the text to the console.\n",
      "Human: The script executed successfully with below output, Answer with only Yes or No if this is the expected output:\n",
      "<output>\n",
      "Hello World!\n",
      "</output>\n",
      "Assistant: Yes\n",
      "\n",
      "\n",
      "Human: You are a helpful AI assistant.\n",
      "\n",
      "You have access to a Bash code interpreter, which supports you in your tasks.\n",
      "The code is executed in an interactive shell, imports and variables are preserved between calls.\n",
      "The environment has internet and file system access.\n",
      "The current working directory is shared with the user, so files can be exchanged.\n",
      "There are many libraries pre-installed, including numpy, pandas, matplotlib, and scikit-learn.\n",
      "You cannot show rich outputs like plots or images, but you can store them in the working directory and point the user to them.\n",
      "If the code runs too long, there will be a timeout.\n",
      "\n",
      "To access the interpreter, use the following format:\n",
      "```bash\n",
      "<your code>\n",
      "```\n",
      "\n",
      "Report expected output and enclose it within a <output></output> tag.\n",
      "If you want to call Bash and still say something, do only output text above the code block, NOT below.\n",
      "Only provide at most one code block per message.\n",
      "The code will be executed automatically and the result will be sent back to you\n",
      "\n",
      "Assistant: Thank you for the explanation. I understand I have access to a Bash interpreter and can execute code by placing it between ```bash tags then return expected output between <output></output> tags. I will use this to assist you with any Bash programming tasks. Just let me know what you need help with!\n",
      "\n",
      "Human:I want a script to print 'Hello World!'\n",
      "Assistant: Here is a simple Bash script to print 'Hello World!':\n",
      "\n",
      "```bash\n",
      "echo 'Hello World!'\n",
      "```\n",
      "\n",
      "<output>\n",
      "Hello World!\n",
      "</output>\n",
      "\n",
      "To print 'Hello World!', we use the echo command. This will output the text contained in quotes to the terminal.\n",
      "Human: The script executed successfully with below output, Answer with only Yes or No if this is the expected output:\n",
      "<output>\n",
      "Hello World!\n",
      "</output>\n",
      "Assistant: Yes\n"
     ]
    }
   ],
   "source": [
    "test_prompts = [\n",
    "    \"I want a script to print 'Hello World!'\",\n",
    "    # \"I want a script that compute first 10 odd numbers and print them.\",\n",
    "    # \"I want a script that compute factorial of 20 and determines the time it took to calculate the result.\",\n",
    "    # \"I want to make tetris game\"\n",
    "]\n",
    "\n",
    "language = \"Java\"\n",
    "for language in LANGUAGES:\n",
    "\n",
    "    params = {\n",
    "        \"display_name\": LANGUAGES[language][\"display_name\"],\n",
    "        \"tag_name\": LANGUAGES[language][\"tag_name\"],\n",
    "        \"error_message\": \"\",\n",
    "        \"script_output\": \"\",\n",
    "        \"language_instructions\": LANGUAGES[language][\"language_instructions\"]\n",
    "    }\n",
    "\n",
    "    for test in test_prompts:\n",
    "        conv = Conversation(\n",
    "            ROLES, \n",
    "            prompt_store.get_prompt_from_template(\n",
    "                \"CI_SYSTEM_PROMPT\",\n",
    "                params\n",
    "            ),\n",
    "            send_req_to_agent,\n",
    "            send_script_to_exc,\n",
    "            extract_script,\n",
    "            language\n",
    "        )\n",
    "        conv.append_chat(\n",
    "            prompt_store.get_prompt_from_template(\n",
    "                \"CI_AGENT_REPLY\",\n",
    "                params\n",
    "            ),\n",
    "            1\n",
    "        )\n",
    "        conv.append_chat(test)\n",
    "        res = conv.send_to_agent_and_exec_script()\n",
    "        max_iterations = 3\n",
    "        i = 0\n",
    "        while i < max_iterations and res[\"error\"]:\n",
    "            i += 1\n",
    "            params[\"error_message\"] = res[\"output\"]\n",
    "            conv.append_chat(\n",
    "                prompt_store.get_prompt_from_template(\n",
    "                    \"CI_SCRIPT_ERROR\",\n",
    "                    params\n",
    "                )\n",
    "            )\n",
    "            conv.send_to_agent_and_exec_script()   \n",
    "        if not res[\"error\"]:\n",
    "            params[\"script_output\"] = res[\"output\"]\n",
    "            conv.append_chat(\n",
    "                prompt_store.get_prompt_from_template(\n",
    "                    \"CI_SCRIPT_SUCCESS\",\n",
    "                    params\n",
    "                )\n",
    "            )\n",
    "            conv.send_to_agent()\n",
    "        print(conv.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a47adea8-6e12-41db-ab2d-d8f812b76683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nHuman: You are a helpful AI assistant.\\n\\nYou have access to a R code interpreter, which supports you in your tasks.\\nThe code is executed in an interactive shell, imports and variables are preserved between calls.\\nThe environment has internet and file system access.\\nThe current working directory is shared with the user, so files can be exchanged.\\nThere are many libraries pre-installed, including numpy, pandas, matplotlib, and scikit-learn.\\nYou cannot show rich outputs like plots or images, but you can store them in the working directory and point the user to them.\\nIf the code runs too long, there will be a timeout.\\n\\nTo access the interpreter, use the following format:\\n```R\\n<your code>\\n```\\nIf you want to call R and still say something, do only output text above the code block, NOT below.\\nOnly provide at most one code block per message.\\nThe code will be executed automatically and the result will be sent back to you\\n\\nAssistant: Thank you for the explanation. I understand I have access to a R interpreter and can execute code by placing it between ```R tags. I will use this to assist you with any R programming tasks. Just let me know what you need help with!\\n\\nHuman:I want a script to print \\'Hello World!\\'\\nAssistant: Here is a simple R script to print \"Hello World!\":\\n\\n```R\\nprint(\"Hello World!\")\\n```\\n\\nThe print() function will output the text passed to it. Let me know if you need any other basic R scripts!'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc5324a-508b-422a-9fc1-3049ece73ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "    parser.add_argument(\"--host\", type=str, default=\"localhost\")\n",
    "    parser.add_argument(\"--port\", type=int, default=8080)\n",
    "    parser.add_argument(\"--api-layer-host\", type=str, default=\"localhost\")\n",
    "    parser.add_argument(\"--api-layer-port\", type=int, default=8080)\n",
    "    parser.add_argument(\"--code-executor-host\", type=str, default=\"localhost\")\n",
    "    parser.add_argument(\"--code-execurtor-port\", type=int, default=8080)\n",
    "    parser.add_argument(\"--prompt-database-file\", type=str, default=\"prompt/database.json\")\n",
    "    parser.add_argument(\"--languages-file\", type=str, default=\"config/languages.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d7722f48-7a50-4b50-8be4-106d85a9b367",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/0)                    docker:m5.xlarge_i-0b845d5e850975fab\n",
      "\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.0s (0/0)                    docker:m5.xlarge_i-0b845d5e850975fab\n",
      "\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.0s (0/2)                    docker:m5.xlarge_i-0b845d5e850975fab\n",
      " => [internal] load .dockerignore                                          0.0s\n",
      " => => transferring context:                                               0.0s\n",
      " => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.2s (2/3)                    docker:m5.xlarge_i-0b845d5e850975fab\n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 310B                                       0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3.10-slim        0.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.3s (2/3)                    docker:m5.xlarge_i-0b845d5e850975fab\n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 310B                                       0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3.10-slim        0.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.5s (2/3)                    docker:m5.xlarge_i-0b845d5e850975fab\n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 310B                                       0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3.10-slim        0.4s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.6s (2/3)                    docker:m5.xlarge_i-0b845d5e850975fab\n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 310B                                       0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3.10-slim        0.6s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.8s (2/3)                    docker:m5.xlarge_i-0b845d5e850975fab\n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 310B                                       0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3.10-slim        0.7s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.9s (11/11) FINISHED         docker:m5.xlarge_i-0b845d5e850975fab\n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 310B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/python:3.10-slim        0.7s\n",
      "\u001b[0m\u001b[34m => [1/6] FROM docker.io/library/python:3.10-slim@sha256:b587fb01826db0ab  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 22.16kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/6] RUN python3 -m pip install uvicorn fastapi -U -q          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [3/6] WORKDIR /code/app                                         0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [4/6] COPY ./requirements.txt /code/requirements.txt            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [5/6] RUN pip install --no-cache-dir --upgrade -r /code/requir  0.0s\n",
      "\u001b[0m\u001b[34m => [6/6] COPY ./app /code/app                                             0.0s\n",
      "\u001b[0m\u001b[34m => exporting to image                                                     0.0s\n",
      "\u001b[0m\u001b[34m => => exporting layers                                                    0.0s\n",
      "\u001b[0m\u001b[34m => => writing image sha256:95961e88e1064d4a15231055f7da6b7314c20b09c3141  0.0s\n",
      "\u001b[0m\u001b[34m => => naming to docker.io/library/controller                              0.0s\n",
      "\u001b[0m\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!docker build --tag controller ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68ac9cf8-78b1-43a3-b6c2-66c3123a8542",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                              DESCRIPTION                               DOCKER ENDPOINT                                               ERROR\n",
      "default                           Current DOCKER_HOST based configuration   unix:///var/run/docker.sock                                   \n",
      "m5.xlarge_i-0b845d5e850975fab *                                             tcp://ip-172-31-73-215.ap-southeast-2.compute.internal:1111   \n"
     ]
    }
   ],
   "source": [
    "!docker context ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40680870-6b7a-40bb-8c6e-bfd22f49a3d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "host_ip = \"ip-172-31-73-215.ap-southeast-2.compute.internal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "caec64af-97b3-4728-bb57-b08ace279f91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bd859ee30828d925484e537e50af1fd3e8ff96a6b9058a9f1eb2f4fdf9069ebf\n"
     ]
    }
   ],
   "source": [
    "%%bash -s $host_ip\n",
    "docker run -d -p 8000:8000 --name test-controller controller --host 0.0.0.0 --port 8000 --api-layer-host ${1} --api-layer-port 8001 --code-executor-host ${1} --code-executor-port 8080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "439cea49-a206-483e-9136-67ee9d5516ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [1]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "!docker logs test-controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2aca18d9-0fab-4c5a-a256-a17ad1752a6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test-controller\n",
      "test-controller\n"
     ]
    }
   ],
   "source": [
    "!docker kill test-controller && docker rm test-controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba214970-2afc-41d3-87fc-46a1f7187743",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test-controller\n"
     ]
    }
   ],
   "source": [
    "!docker rm test-controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb2a55e3-52ea-4853-a825-fe892d5dcdc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    22  100    22    0     0   1684      0 --:--:-- --:--:-- --:--:--  2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Health_Check\":\"200\"}"
     ]
    }
   ],
   "source": [
    "%%bash -s $host_ip\n",
    "curl http://${1}:8000/ping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0da29c48-c893-4140-83fc-a468e7b4bae1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   975  100   975    0     0   133k      0 --:--:-- --:--:-- --:--:--  136k\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"{\\\"Python\\\": {\\\"display_name\\\": \\\"Python\\\", \\\"kernel_name\\\": \\\"python3\\\", \\\"tag_name\\\": \\\"python\\\", \\\"language_instructions\\\": \\\"\\\", \\\"pre_exec_script\\\": null, \\\"post_exec_script\\\": null}, \\\"R\\\": {\\\"display_name\\\": \\\"R\\\", \\\"kernel_name\\\": \\\"ir\\\", \\\"tag_name\\\": \\\"R\\\", \\\"language_instructions\\\": \\\"\\\", \\\"pre_exec_script\\\": null, \\\"post_exec_script\\\": null}, \\\"Java\\\": {\\\"display_name\\\": \\\"Java\\\", \\\"kernel_name\\\": \\\"java\\\", \\\"tag_name\\\": \\\"java\\\", \\\"language_instructions\\\": \\\"Always use \\\\\\\"Main\\\\\\\" as class name.\\\", \\\"pre_exec_script\\\": null, \\\"post_exec_script\\\": \\\"Main.main(new String[] {})\\\"}, \\\"JavaScript\\\": {\\\"display_name\\\": \\\"JavaScript\\\", \\\"kernel_name\\\": \\\"javascript\\\", \\\"tag_name\\\": \\\"js\\\", \\\"language_instructions\\\": \\\"\\\", \\\"pre_exec_script\\\": null, \\\"post_exec_script\\\": null}, \\\"Bash\\\": {\\\"display_name\\\": \\\"Bash\\\", \\\"kernel_name\\\": \\\"bash\\\", \\\"tag_name\\\": \\\"bash\\\", \\\"language_instructions\\\": \\\"\\\", \\\"pre_exec_script\\\": null, \\\"post_exec_script\\\": null}}\""
     ]
    }
   ],
   "source": [
    "%%bash -s $host_ip\n",
    "curl http://${1}:8000/list_languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a2d4f240-7c5a-4e21-addf-bf2d9d3413a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   524  100   398  100   126    144     45  0:00:02  0:00:02 --:--:--   190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"script\":\"console.log(\\\"Hello World\\\");\",\"expected_output\":\"Hello World\",\"generated_text\":\" Here is some code to print \\\"Hello World\\\" in JavaScript:\\n\\n```js\\nconsole.log(\\\"Hello World\\\");\\n```\\n\\n<output>\\nHello World\\n</output>\\n\\nTo print \\\"Hello World\\\" to the console in JavaScript, you can use console.log() and pass the string \\\"Hello World\\\" as a parameter.\",\"conv_id\":\"8fd0ee1dbd87484c\"}"
     ]
    }
   ],
   "source": [
    "%%bash -s $host_ip\n",
    "curl http://${1}:8000/generate -d '{\"prompt\": \"Write Hello World code\", \"model_family\": \"bedrock\", \"model_name\": \"anthropic.claude-v2\", \"language\": \"JavaScript\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe61897-a333-4d9b-91a9-51e20bddd821",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s $host_ip\n",
    "curl http://${1}:8000/execute -d '{\"script\": \"console.log(\\\"Hello World\\\");\", \"expected_output\":\"Hello World\", \"model_family\": \"bedrock\", \"model_name\": \"anthropic.claude-v2\", \"language\": \"JavaScript\", \"conv_id\":\"8fd0ee1dbd87484c\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4cd7a65a-bd4e-4f1e-aa58-9dc915cbc7d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  1187  100   993  100   194    285     55  0:00:03  0:00:03 --:--:--   341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"script\":\"console.log(\\\"Hello World\\\");\",\"expected_output\":\"Hello World  \",\"generated_text\":\" Here is the corrected script:\\n\\n```js\\nconsole.log(\\\"Hello World\\\");\\n```\\n\\n<output>\\nHello World  \\n</output>\\n\\nThe issue was that the original code was missing a closing quotation mark after \\\"Hello World\\\" in the console.log statement, which caused a syntax error. I've added the closing quotation mark to fix it.\",\"conv_id\":\"8fd0ee1dbd87484c\",\"output\":\"evalmachine.<anonymous>:1\\nconsole.log(\\\"Hello World);\\n            ^^^^^^^^^^^^^^\\n\\nSyntaxError: Invalid or unexpected token\\n    at new Script (node:vm:93:7)\\n    at createScript (node:vm:248:10)\\n    at Object.runInThisContext (node:vm:296:10)\\n    at run ([eval]:1020:15)\\n    at onRunRequest ([eval]:864:18)\\n    at onMessage ([eval]:828:13)\\n    at process.emit (node:events:514:28)\\n    at emit (node:internal/child_process:951:14)\\n    at process.processTicksAndRejections (node:internal/process/task_queues:83:21)\",\"error\":true}"
     ]
    }
   ],
   "source": [
    "%%bash -s $host_ip\n",
    "curl http://${1}:8000/execute -d '{\"script\": \"console.log(\\\"Hello World);\", \"expected_output\":\"Hello World\", \"model_family\": \"bedrock\", \"model_name\": \"anthropic.claude-v2\", \"language\": \"JavaScript\", \"conv_id\":\"8fd0ee1dbd87484c\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bf4d91-cf93-4917-a6c0-f8404d84ee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    script = params.get(\"script\")\n",
    "    expected_output = params.get(\"expected_output\", \"\")\n",
    "    model_family = params.get(\"model_family\")\n",
    "    model_name = params.get(\"model_name\")\n",
    "    language = params.get(\"language\")\n",
    "    conv_id = params.get(\"conv_id\")\n",
    "    if not (script and conv_id and model_family and model_name and language):\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "43f269ca-3379-4680-966b-1e0628fe2211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY      TAG       IMAGE ID       CREATED             SIZE\n",
      "controller      latest    afe70ea65b75   About an hour ago   237MB\n",
      "<none>          <none>    931a9fa402fe   3 hours ago         235MB\n",
      "code-executor   latest    0e3269ad5dc3   3 hours ago         7.21GB\n",
      "api-layer       latest    0399a50f1f6b   3 hours ago         236MB\n"
     ]
    }
   ],
   "source": [
    "!docker images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bea074ec-8f2b-4647-bdc5-74863b69ac4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE                  COMMAND                  CREATED             STATUS                   PORTS                              NAMES\n",
      "2b0dc9ab993b   controller             \"python3 /code/app/m…\"   About an hour ago   Up About an hour         0.0.0.0:8000->8000/tcp             test-controller\n",
      "748998feca14   api-layer:latest       \"python3 /code/app/m…\"   2 hours ago         Up 2 hours               0.0.0.0:8001->8001/tcp             test-api-layer\n",
      "28521fe9da3c   931a9fa402fe           \"python3 /code/app/m…\"   3 hours ago         Exited (1) 3 hours ago                                      magical_dubinsky\n",
      "84a36276d3e2   931a9fa402fe           \"python3 /code/app/m…\"   3 hours ago         Created                                                     beautiful_bhabha\n",
      "ce38cebb9925   code-executor:latest   \"python3 /code/app/m…\"   3 hours ago         Up 3 hours (unhealthy)   0.0.0.0:8080->8080/tcp, 8888/tcp   test\n"
     ]
    }
   ],
   "source": [
    "!docker ps --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8cae3bde-7725-42a8-b676-19eb78705c4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28521fe9da3c\n",
      "84a36276d3e2\n"
     ]
    }
   ],
   "source": [
    "!docker rm 28521fe9da3c 84a36276d3e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "53fbe0b4-0461-456f-8236-5b53a07a64d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: sha256:931a9fa402fe2658ffcaf29d4496b9c926a70688040e6b9579421b7b1279d12c\n"
     ]
    }
   ],
   "source": [
    "!docker rmi 931"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84f11d6-ffe4-449a-9d5e-b39e910ba96d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-2:452832661640:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "lcc_arn": "arn:aws:sagemaker:ap-southeast-2:734840029783:studio-lifecycle-config/sdocker-kg"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
