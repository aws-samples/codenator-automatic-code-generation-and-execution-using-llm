{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ad0e68f-8280-444c-a2d0-a61b451b6fe2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.3.3 requires pyqt5<5.16, which is not installed.\n",
      "spyder 5.3.3 requires pyqtwebengine<5.16, which is not installed.\n",
      "distributed 2022.7.0 requires tornado<6.2,>=6.0.3, but you have tornado 6.3.3 which is incompatible.\n",
      "jupyterlab 3.4.4 requires jupyter-server~=1.16, but you have jupyter-server 2.7.3 which is incompatible.\n",
      "jupyterlab-server 2.10.3 requires jupyter-server~=1.4, but you have jupyter-server 2.7.3 which is incompatible.\n",
      "notebook 6.5.5 requires jupyter-client<8,>=5.3.4, but you have jupyter-client 8.3.1 which is incompatible.\n",
      "notebook 6.5.5 requires pyzmq<25,>=17, but you have pyzmq 25.1.1 which is incompatible.\n",
      "panel 0.13.1 requires bokeh<2.5.0,>=2.4.0, but you have bokeh 3.2.2 which is incompatible.\n",
      "spyder 5.3.3 requires ipython<8.0.0,>=7.31.1, but you have ipython 8.15.0 which is incompatible.\n",
      "spyder 5.3.3 requires pylint<3.0,>=2.5.0, but you have pylint 3.0.0a7 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install gradio -U -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3fa74c53-1bff-4be7-b14a-fc0628bfc010",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "Thanks for being a Gradio user! If you have questions or feedback, please join our Discord server and chat with us: https://discord.gg/feTf9x3ZSB\n",
      "Sagemaker notebooks may require sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Running on public URL: https://61ab7f50e0c7ce9cb9.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://61ab7f50e0c7ce9cb9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n",
      "Killing tunnel 127.0.0.1:7861 <> https://0516bcd1d5391d01e7.gradio.live\n",
      "Killing tunnel 127.0.0.1:7861 <> https://61ab7f50e0c7ce9cb9.gradio.live\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "import gradio as gr\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Global\n",
    "controller_url = \"ip-172-31-70-124.ap-southeast-2.compute.internal\" + \":8000\"\n",
    "\n",
    "l_mapping = {\n",
    "    \"Bash\":\"shell\", \n",
    "    \"Python\":\"python\", \n",
    "    \"Java\":\"javascript\",\n",
    "    \"JavaScript\":\"javascript\", \n",
    "    \"R\":\"r\"\n",
    "}\n",
    "models_list = {\n",
    "    \"Claude-v2\": {\n",
    "        \"model_family\": \"bedrock\",\n",
    "        \"model_name\": \"anthropic.claude-v2\"\n",
    "    }\n",
    "}\n",
    "\n",
    "css = \"\"\"\n",
    "#red {background-color: #FA9F9D}\n",
    "#amber {background-color: #FFD966}\n",
    ".gradio-container {margin: 0 !important}\n",
    ".app.svelte-1kyws56.svelte-1kyws56 {\n",
    "  max-width: 2100px;\n",
    "}\n",
    "\"\"\"\n",
    "    \n",
    "def execute_fn(state, history, script, exp_out, model, language):\n",
    "    data = json.dumps(\n",
    "        {\n",
    "            \"script\": script,\n",
    "            \"model_family\": models_list[model][\"model_family\"], \n",
    "            \"model_name\": models_list[model][\"model_name\"], \n",
    "            \"language\": language,\n",
    "            \"expected_output\": exp_out,\n",
    "            \"conv_id\": state\n",
    "        }\n",
    "    )\n",
    "    response = requests.post(\n",
    "            \"http://\" + controller_url + \"/execute\",\n",
    "            data=data\n",
    "        ).json()\n",
    "    if response[\"error\"]:\n",
    "        out = gr.Textbox(value=response[\"output\"],label=\"Output: ‚ùåÔ∏è EERROR ‚ùåÔ∏è\", elem_id=\"red\")\n",
    "        history.append([\"The script failed with shown error message\", response[\"generated_text\"]])\n",
    "        script = response[\"script\"]\n",
    "    else:\n",
    "        if response[\"output\"] != exp_out:\n",
    "            out = gr.Textbox(value=response[\"output\"],label=\"Output: ‚ö†Ô∏è WARNING ‚ö†Ô∏è value does not match `Expected Output`\", elem_id=\"amber\", interactive=False, show_copy_button=True, lines=7)\n",
    "        else:\n",
    "            out = gr.Textbox(value=response[\"output\"],label=\"Output:\", elem_id=\"--primary-50\", interactive=False, show_copy_button=True, lines=7)\n",
    "    return [history, out, script] \n",
    "\n",
    "\n",
    "def can_exec(script):\n",
    "    if script != \"\":\n",
    "        return gr.Button(value=\"Approve and Execute\", interactive=True)\n",
    "    else:\n",
    "        return gr.Button(value=\"Approve and Execute\", interactive=False)\n",
    "\n",
    "    \n",
    "def Dropdown_lang(dropdown, script):\n",
    "    \"\"\"\n",
    "    Code Languages\n",
    "    approved language: [('python', 'markdown', 'json', 'html', 'css', 'javascript', 'typescript', 'yaml', 'dockerfile', 'shell', 'r')]\n",
    "    \"\"\"\n",
    "    return [gr.Code(value=script, language=l_mapping[dropdown], interactive=False), \"\"]\n",
    "\n",
    "def clear_fn():\n",
    "    return [\"\"] * 3 + [gr.Textbox(value=\"\",label=\"Output\", elem_id=\"--primary-50\", interactive=False, show_copy_button=True, lines=7)]\n",
    "\n",
    "def pass_chat(message, history):\n",
    "    return \"\"\n",
    "\n",
    "def generate_response(state, message, history, model, language): \n",
    "    \"\"\"\n",
    "    Sample Response - to be deleted\n",
    "    \"\"\"\n",
    "    data = json.dumps(\n",
    "        {\n",
    "            \"prompt\": message,\n",
    "            \"model_family\": models_list[model][\"model_family\"], \n",
    "            \"model_name\": models_list[model][\"model_name\"], \n",
    "            \"language\": language,\n",
    "            \"conv_id\": state\n",
    "        }\n",
    "    )\n",
    "    response = requests.post(\n",
    "            \"http://\" + controller_url + \"/generate\",\n",
    "            data=data\n",
    "        ).json()\n",
    "    state = response[\"conv_id\"]\n",
    "    history += [[message, response[\"generated_text\"]]]\n",
    "    return [state, history, response[\"script\"], response[\"expected_output\"]]\n",
    "\n",
    "def web_ui():\n",
    "    with gr.Blocks(css=css, theme=gr.themes.Base(neutral_hue=\"slate\")) as webUI:\n",
    "        state = gr.State(value=\"\")\n",
    "        gr.Markdown(\n",
    "            \"\"\"\n",
    "            # Welcome to SynthCodeX ü§ñÔ∏è\n",
    "            ### Use this tool to generate and test code using LLMs\n",
    "            \"\"\")\n",
    "        with gr.Row(equal_height=True):\n",
    "            with gr.Column(scale=2):\n",
    "                chat = gr.ChatInterface(\n",
    "                    pass_chat, \n",
    "                    undo_btn=None, \n",
    "                    retry_btn=None\n",
    "                )\n",
    "            with gr.Column(scale=1):\n",
    "                with gr.Group():\n",
    "                    language = gr.Dropdown(languages,label='Langauge Selection', value=languages[0]) # Langauge Selection\n",
    "                    model = gr.Dropdown(models_list.keys(),label=\"Model Selection\", value=list(models_list.keys())[0]) # Model Selection\n",
    "                    script = gr.Code(value=\"\",label=\"Script\", language = l_mapping[languages[0]], interactive=False)\n",
    "                    exp_out = gr.Textbox(value=\"\",label=\"Expected Output\", interactive=False)\n",
    "                    execute = gr.Button(value=\"Approve and Execute\", interactive=False)\n",
    "        out = gr.Textbox(value=\"\",label=\"Output\", interactive=False, show_copy_button=True, lines=7)\n",
    "        with gr.Accordion(label=\"Parameters\", open=False):\n",
    "            auto_run = gr.Checkbox(label='Auto-approve and Execute')\n",
    "            timeout = gr.Number(label=\"Timeout\", precision=0, minimum=0, maximum=60)\n",
    "            \n",
    "        language.change(Dropdown_lang, [language, script], [script, out])\n",
    "        script.change(can_exec, script, execute)\n",
    "        chat.submit_btn.click(generate_response, [state, chat.textbox, chat.chatbot, model, language], [state, chat.chatbot, script, exp_out])\n",
    "        chat.textbox.submit(generate_response, [state, chat.textbox, chat.chatbot, model, language], [state, chat.chatbot, script, exp_out])\n",
    "        chat.clear_btn.click(clear_fn, None, [state, script, exp_out, out])\n",
    "        execute.click(execute_fn, [state, chat.chatbot, script, exp_out, model, language], [chat.chatbot, out, script])\n",
    "    return webUI\n",
    "\n",
    "def get_languages_list(url):\n",
    "    return list(json.loads(requests.get(\"http://\" + url + \"/list_languages\").json()).keys())\n",
    "    \n",
    "if __name__ == \"__main__\":    \n",
    "    languages = get_languages_list(controller_url)\n",
    "    UI = web_ui()\n",
    "    UI.launch(debug=True)\n",
    "\n",
    "    # create events, when chaning model/language selection, it will clear the chat history, scirpt, expected output and output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384b5a0f-08a4-4e4a-b636-411014e46dd4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Reset Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e548614-e140-48b0-8ca9-402878cd760f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def converse(x, y, z):\n",
    "    return z\n",
    "\n",
    "def reset(z):\n",
    "    return [], []\n",
    "\n",
    "# Gradio app\n",
    "with gr.Blocks() as demo:\n",
    "    bot = gr.Chatbot(render=False)\n",
    "    dropdown = gr.Dropdown([\"Character 1\", \"Character 2\", \"Character 3\"], label=\"Characters\", info=\"Select the character that you'd like to speak to\", value=\"Character 1\")\n",
    "    chat = gr.ChatInterface(\n",
    "        fn=converse,\n",
    "        chatbot=bot,\n",
    "        additional_inputs=dropdown\n",
    "    )\n",
    "    dropdown.input(fn=reset, inputs=dropdown, outputs=[bot, chat.chatbot_state])\n",
    "\n",
    "demo.queue()\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0f7cd313-1fe8-4088-9886-cea387797db7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://ip-172-31-73-215.ap-southeast-2.compute.internal:8000/generate'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"http://\" + controller_url + \"/generate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2929aec4-28d6-4149-91f0-8ca15a9a2eff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-2:452832661640:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "lcc_arn": "arn:aws:sagemaker:ap-southeast-2:734840029783:studio-lifecycle-config/sdocker-kg"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
